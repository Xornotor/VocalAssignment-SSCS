{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SSCS - Test Playground - tf.data**\n",
    "\n",
    "Developed by André Paiva\n",
    "\n",
    "Based on SSCS Dataset created by Helena Cuesta and Emilia Gómez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXECUTE_ON_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy, Precision\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 3\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(num_threads)\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = str(num_threads)\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = str(num_threads)\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_threads)\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Neural Network Model (VoasCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = True\n",
    "SPLIT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voas_cnn_model():\n",
    "    x_in = Input(shape=(360, SPLIT_SIZE, 1))\n",
    "    \n",
    "    x = BatchNormalization()(x_in)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv1\")(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv2\")(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=16, kernel_size=(70, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv_harm_1\")(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=16, kernel_size=(70, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv_harm_2\")(x)\n",
    "\n",
    "    ## start four branches now\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    ## branch 1\n",
    "    x1a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv1a\")(x)\n",
    "\n",
    "    x1a = BatchNormalization()(x1a)\n",
    "\n",
    "    x1b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv1b\")(x1a)\n",
    "\n",
    "    ## branch 2\n",
    "    x2a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv2a\")(x)\n",
    "\n",
    "    x2a = BatchNormalization()(x2a)\n",
    "\n",
    "    x2b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv2b\")(x2a)\n",
    "\n",
    "    ## branch 3\n",
    "\n",
    "    x3a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv3a\")(x)\n",
    "\n",
    "    x3a = BatchNormalization()(x3a)\n",
    "\n",
    "    x3b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv3b\")(x3a)\n",
    "\n",
    "    x4a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv4a\")(x)\n",
    "\n",
    "    x4a = BatchNormalization()(x4a)\n",
    "\n",
    "    x4b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv4b\"\n",
    "    )(x4a)\n",
    "\n",
    "\n",
    "    y1 = Conv2D(filters=1, kernel_size=1, name='conv_soprano',\n",
    "                padding='same', activation='sigmoid')(x1b)\n",
    "    y1 = tf.squeeze(y1, axis=-1)\n",
    "    y2 = Conv2D(filters=1, kernel_size=1, name='conv_alto',\n",
    "                padding='same', activation='sigmoid')(x2b)\n",
    "    y2 = tf.squeeze(y2, axis=-1)\n",
    "    y3 = Conv2D(filters=1, kernel_size=1, name='conv_tenor',\n",
    "                padding='same', activation='sigmoid')(x3b)\n",
    "    y3 = tf.squeeze(y3, axis=-1)\n",
    "    y4 = Conv2D(filters=1, kernel_size=1, name='conv_bass',\n",
    "                padding='same', activation='sigmoid')(x4b)\n",
    "    y4 = tf.squeeze(y4, axis=-1)\n",
    "\n",
    "    out = [y1, y2, y3, y4]\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=out, name='voasCNN')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Auxiliar functions and Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions designed to manipulate the SSCS dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - File path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(EXECUTE_ON_COLAB):\n",
    "    dataset_dir = \"/content/Datasets/\"\n",
    "else:\n",
    "    dataset_dir = \"Datasets/\"\n",
    "zipname = dataset_dir + \"SSCS_HDF5.zip\"\n",
    "sscs_dir = dataset_dir + \"SSCS_HDF5/\"\n",
    "\n",
    "songs_dir = sscs_dir + \"sscs/\"\n",
    "splitname = sscs_dir + \"sscs_splits.json\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Download/Extract Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, fname):\n",
    "    \n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get('content-length', 0))\n",
    "    downloaded_size = 0\n",
    "    with open(fname, 'wb') as file:\n",
    "        for data in resp.iter_content(chunk_size=max(4096, int(total/10000))):\n",
    "            size = file.write(data)\n",
    "            downloaded_size += size\n",
    "            percent = min(downloaded_size/total, 1.0)\n",
    "            print(f\"\\r{percent:.2%} downloaded\", end='')\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_download():\n",
    "    \n",
    "    if(not os.path.exists(dataset_dir)):\n",
    "        os.mkdir(dataset_dir)\n",
    "   \n",
    "    if(not os.path.exists(zipname)):\n",
    "        print(\"Downloading SSCS Dataset...\")\n",
    "        url = \"https://github.com/Xornotor/SSCS_HDF5/releases/download/v1.0/SSCS_HDF5.zip\"\n",
    "        download(url, zipname)\n",
    "    else:\n",
    "        print(\"SSCS Dataset found.\")\n",
    "\n",
    "    if(not os.path.exists(sscs_dir)):\n",
    "        print(\"Extracting SSCS Dataset...\")\n",
    "        with zipfile.ZipFile(zipname) as zf:\n",
    "            os.mkdir(sscs_dir)\n",
    "            zf.extractall(path=sscs_dir)\n",
    "    else:\n",
    "        print(\"SSCS Dataset already extracted.\")\n",
    "    \n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Download and extract dataset SSCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscs_download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
