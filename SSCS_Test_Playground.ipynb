{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SSCS - Test Playground**\n",
    "\n",
    "Developed by André Paiva\n",
    "\n",
    "Based on SSCS Dataset created by Helena Cuesta and Emilia Gómez"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** if you're running this notebook on Google Colab, please **uncomment the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip --quiet install ray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import requests\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "ray.init(num_cpus=num_cpus, ignore_reinit_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Neural Network Model (VoasCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = True\n",
    "SPLIT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voas_cnn_model():\n",
    "    x_in = Input(shape=(360, SPLIT_SIZE, 1))\n",
    "    \n",
    "    x = BatchNormalization()(x_in)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv1\")(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv2\")(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=16, kernel_size=(70, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv_harm_1\")(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=16, kernel_size=(70, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv_harm_2\")(x)\n",
    "\n",
    "    ## start four branches now\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    ## branch 1\n",
    "    x1a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv1a\")(x)\n",
    "\n",
    "    x1a = BatchNormalization()(x1a)\n",
    "\n",
    "    x1b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv1b\")(x1a)\n",
    "\n",
    "    ## branch 2\n",
    "    x2a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv2a\")(x)\n",
    "\n",
    "    x2a = BatchNormalization()(x2a)\n",
    "\n",
    "    x2b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv2b\")(x2a)\n",
    "\n",
    "    ## branch 3\n",
    "\n",
    "    x3a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv3a\")(x)\n",
    "\n",
    "    x3a = BatchNormalization()(x3a)\n",
    "\n",
    "    x3b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv3b\")(x3a)\n",
    "\n",
    "    x4a = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv4a\")(x)\n",
    "\n",
    "    x4a = BatchNormalization()(x4a)\n",
    "\n",
    "    x4b = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",\n",
    "        activation=\"relu\", name=\"conv4b\"\n",
    "    )(x4a)\n",
    "\n",
    "\n",
    "    y1 = Conv2D(filters=1, kernel_size=1, name='conv_soprano',\n",
    "                padding='same', activation='sigmoid')(x1b)\n",
    "    y1 = tf.squeeze(y1, axis=-1)\n",
    "    y2 = Conv2D(filters=1, kernel_size=1, name='conv_alto',\n",
    "                padding='same', activation='sigmoid')(x2b)\n",
    "    y2 = tf.squeeze(y2, axis=-1)\n",
    "    y3 = Conv2D(filters=1, kernel_size=1, name='conv_tenor',\n",
    "                padding='same', activation='sigmoid')(x3b)\n",
    "    y3 = tf.squeeze(y3, axis=-1)\n",
    "    y4 = Conv2D(filters=1, kernel_size=1, name='conv_bass',\n",
    "                padding='same', activation='sigmoid')(x4b)\n",
    "    y4 = tf.squeeze(y4, axis=-1)\n",
    "\n",
    "    out = [y1, y2, y3, y4]\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=out, name='voasCNN')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Auxiliar functions and Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions designed to manipulate the SSCS dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - File path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"Datasets\"\n",
    "zipname = dataset_dir + \"/SynthSalienceChoralSet_v1.zip\"\n",
    "splitname = dataset_dir + \"/SynthSalienceChoralSet_dataSplits.json\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Download Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, fname):\n",
    "    \n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get('content-length', 0))\n",
    "    downloaded_size = 0\n",
    "    with open(fname, 'wb') as file:\n",
    "        for data in resp.iter_content(chunk_size=max(4096, int(total/10000))):\n",
    "            size = file.write(data)\n",
    "            downloaded_size += size\n",
    "            percent = min(downloaded_size/total, 1.0)\n",
    "            print(f\"\\r{percent:.2%} downloaded\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_download():\n",
    "    \n",
    "    if(not os.path.exists(dataset_dir)):\n",
    "        os.mkdir(dataset_dir)\n",
    "   \n",
    "    if(not os.path.exists(splitname)):\n",
    "        print(\"Downloading SSCS Splits JSON...\")\n",
    "        url = \"https://raw.githubusercontent.com/helenacuesta/voas-vocal-quartets/main/data/data_splits_hpc.json\"\n",
    "        download(url, splitname)\n",
    "    else:\n",
    "        print(\"SSCS Splits JSON found.\")\n",
    "\n",
    "    if(not os.path.exists(zipname)):\n",
    "        print(\"Downloading SSCS Dataset...\")\n",
    "        url = \"https://zenodo.org/record/6534429/files/SynthSalienceChoralSet_v1.zip?download=1\"\n",
    "        download(url, zipname)\n",
    "    else:\n",
    "        print(\"SSCS Dataset found.\")\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Splits, songnames and songlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_get_split(split='train'):\n",
    "    \n",
    "    if(split.lower() == 'train' or split.lower() == 'validate' or\n",
    "       split.lower() == 'test'):\n",
    "        return json.load(open(splitname, 'r'))[split.lower()]\n",
    "    else:\n",
    "        raise NameError(\"Split should be 'train', 'validate' or 'test'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_pick_songlist(first=0, amount=5, split='train'):\n",
    "    \n",
    "    songnames = sscs_get_split(split)\n",
    "    return songnames[first:first+amount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_pick_random_song(split='train'):\n",
    "    \n",
    "    songnames = sscs_get_split(split)\n",
    "    rng = np.random.randint(0, len(songnames))\n",
    "    return songnames[rng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_pick_multiple_random_songs(amount, split='train'):\n",
    "    \n",
    "    return [sscs_pick_random_song() for i in range(amount)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Access to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_read_metadata():\n",
    "    \n",
    "    with zipfile.ZipFile(zipname) as zf:\n",
    "        with zf.open(\"sscs_metadata.csv\") as f:\n",
    "            df = pd.read_csv(f, engine='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Read voices from songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sscs_read_voice(name, voice):\n",
    "    \n",
    "    filename = 'sscs/' + name + \"_\"\n",
    "    if(voice.upper() == 'S' or voice.upper() == 'A' or \\\n",
    "       voice.upper() == 'T' or voice.upper() == 'B'):\n",
    "        filename = filename + voice.upper()\n",
    "    elif(voice.lower() == 'mix'):\n",
    "        filename = filename + voice.lower()\n",
    "    else:\n",
    "        raise NameError(\"Specify voice with 'S', 'A', 'T', 'B' or 'mix'.\")\n",
    "    filename = filename + \".csv\"\n",
    "    with zipfile.ZipFile(zipname) as zf:\n",
    "        with zf.open(filename) as f:\n",
    "            df = pd.read_csv(f, header=None, engine='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_read_all_voices(name):\n",
    "    \n",
    "    voices = ['mix', 'S', 'A', 'T', 'B']\n",
    "    data_access = [sscs_read_voice.remote(name, voice) for voice in voices]\n",
    "    df_voices = ray.get(data_access)\n",
    "    mix = df_voices[0]\n",
    "    satb = df_voices[1:]\n",
    "    return mix, satb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Create splits from voices (for training the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sscs_split_and_reshape(df, split_size):\n",
    "    \n",
    "    split_arr = np.array_split(df, df.shape[1]/split_size, axis=1)\n",
    "    split_arr = np.array([i.iloc[:, :split_size] for i in split_arr])\n",
    "    return split_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sscs_read_all_voice_splits(name, split_size):\n",
    "    mix_raw, satb_raw = sscs_read_all_voices(name)\n",
    "    df_voices = satb_raw\n",
    "    df_voices.insert(0, mix_raw)\n",
    "    voice_splits = [sscs_split_and_reshape.remote(df, split_size) for df in df_voices]\n",
    "    mix_splits = ray.get(voice_splits)[0]\n",
    "    s_splits = ray.get(voice_splits)[1]\n",
    "    a_splits = ray.get(voice_splits)[2]\n",
    "    t_splits = ray.get(voice_splits)[3]\n",
    "    b_splits = ray.get(voice_splits)[4]\n",
    "    return mix_splits, s_splits, a_splits, t_splits, b_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_read_multiple_songs_splits(split_size, first=0, amount=5, split='train'):\n",
    "    \n",
    "    songlist = sscs_pick_songlist(first, amount, split)\n",
    "    split_access = [sscs_read_all_voice_splits.remote(song, split_size) \\\n",
    "                    for song in songlist]\n",
    "    split_list = ray.get(split_access)\n",
    "\n",
    "    mix_list = [split_list[i][0] for i in range(amount)]\n",
    "    s_list = [split_list[i][1] for i in range(amount)]\n",
    "    a_list = [split_list[i][2] for i in range(amount)]\n",
    "    t_list = [split_list[i][3] for i in range(amount)]\n",
    "    b_list = [split_list[i][4] for i in range(amount)]\n",
    "\n",
    "    mix_splits = np.concatenate(mix_list, axis=0)\n",
    "    s_splits = np.concatenate(s_list, axis=0)\n",
    "    a_splits = np.concatenate(a_list, axis=0)\n",
    "    t_splits = np.concatenate(t_list, axis=0)\n",
    "    b_splits = np.concatenate(b_list, axis=0)\n",
    "    \n",
    "    return mix_splits, s_splits, a_splits, t_splits, b_splits\n",
    "\n",
    "\n",
    "# Alias\n",
    "sscs_get_data = sscs_read_multiple_songs_splits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 - Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_plot(dataframe):\n",
    "\n",
    "    aspect_ratio = (3/8)*dataframe.shape[1]/dataframe.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(13, 7))\n",
    "    im = ax.imshow(dataframe, interpolation='nearest', aspect=aspect_ratio,\n",
    "        cmap = mpl.colormaps['BuPu'])\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_plot_random(voice, split='train'):\n",
    "    \n",
    "    random_song = sscs_pick_random_song(split)\n",
    "    sscs_plot(ray.get(sscs_read_voice.remote(random_song, voice)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - Download dataset SSCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscs_download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - Pick random song and plot mix pitch saliences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscs_plot_random('mix')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - Getting data splits for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix, s, a, t, b = sscs_get_data(SPLIT_SIZE, amount=5)\n",
    "print(mix.shape, s.shape, a.shape, t.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(mix, s, a, t, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "voas_cnn = voas_cnn_model()\n",
    "voas_cnn.compile(optimizer=Adam(learning_rate=5e-3),\n",
    "                 loss=BinaryCrossentropy(),\n",
    "                 metrics=[Accuracy()])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
