{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSCS dataset conversion to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import zipfile\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipname = \"Datasets/SynthSalienceChoralSet_v1.zip\"\n",
    "h5_pathname = \"Datasets/HDF5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_conformity(name):\n",
    "    return re.sub(\"[~\\\"#%&*:<>?/\\\\{|}]\", \"\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_get_split(split='train'):\n",
    "    splitname = \"Datasets/SynthSalienceChoralSet_dataSplits.json\"\n",
    "    if(split.lower() == 'train' or split.lower() == 'validate' or\n",
    "       split.lower() == 'test'):\n",
    "        return json.load(open(splitname, 'r'))[split.lower()]\n",
    "    else:\n",
    "        raise NameError(\"Split should be 'train', 'validate' or 'test'.\")\n",
    "    \n",
    "train = sscs_get_split()\n",
    "validate = sscs_get_split('validate')\n",
    "test = sscs_get_split('test')\n",
    "\n",
    "train_conformity = [name_conformity(name) for name in train]\n",
    "validate_conformity = [name_conformity(name) for name in validate]\n",
    "test_conformity = [name_conformity(name) for name in test]\n",
    "\n",
    "hdf5_metadata = {}\n",
    "hdf5_metadata['train'] = train_conformity\n",
    "hdf5_metadata['validate'] = validate_conformity\n",
    "hdf5_metadata['test'] = test_conformity\n",
    "\n",
    "metadata_filename = h5_pathname + \"SynthSalienceChoralSet_hdf5_dataSplits.json\"\n",
    "with open(metadata_filename, \"w\") as metadata_file:\n",
    "    json.dump(hdf5_metadata, metadata_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(songname):\n",
    "    with zipfile.ZipFile(zipname) as zf:\n",
    "        fname = \"sscs/\" + songname\n",
    "        with zf.open(fname) as f:\n",
    "            df = pd.read_csv(f, header=None, engine='pyarrow')\n",
    "        df = df.T\n",
    "        return df\n",
    "  \n",
    "def csv_to_hdf5(songname, songname_conformity):\n",
    "    fnames   = [songname + \"_mix.csv\",\n",
    "                songname + \"_S.csv\",\n",
    "                songname + \"_A.csv\",\n",
    "                songname + \"_T.csv\",\n",
    "                songname + \"_B.csv\"] \n",
    "    keynames = ['mix', 'voice/soprano', 'voice/alto',\n",
    "                'voice/tenor', 'voice/bass']\n",
    "    savename = h5_pathname + \"Files/\" + songname_conformity + \".h5\"\n",
    "    for i in range(5):\n",
    "        df = csv_to_df(fnames[i])\n",
    "        df.to_hdf(savename, keynames[i], mode='a',\n",
    "                  format='table', complevel=9, complib='blosc')\n",
    "        del(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_plot(dataframe):\n",
    "\n",
    "    aspect_ratio = (3/8)*dataframe.shape[1]/dataframe.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(13, 7))\n",
    "    im = ax.imshow(dataframe, interpolation='nearest', aspect=aspect_ratio,\n",
    "        cmap = mpl.colormaps['BuPu'])\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    csv_to_hdf5(train[i], train_conformity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(validate)):\n",
    "    csv_to_hdf5(validate[i], validate_conformity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    csv_to_hdf5(test[i], test_conformity[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
