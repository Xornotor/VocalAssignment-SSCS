{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSCS dataset conversion to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import zipfile\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import ray\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "ray.init(num_cpus=num_cpus, num_gpus=0, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipname = \"Datasets/SynthSalienceChoralSet_v1.zip\"\n",
    "h5_pathname = \"Datasets/HDF5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_conformity(name):\n",
    "    return re.sub(\"[~\\\"#%&*:<>?/\\\\{|}]\", \"\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscs_get_split(split='train'):\n",
    "    splitname = \"Datasets/SynthSalienceChoralSet_dataSplits.json\"\n",
    "    if(split.lower() == 'train' or split.lower() == 'validate' or\n",
    "       split.lower() == 'test'):\n",
    "        return json.load(open(splitname, 'r'))[split.lower()]\n",
    "    else:\n",
    "        raise NameError(\"Split should be 'train', 'validate' or 'test'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIntegrity(songlist):\n",
    "\n",
    "    count = 0\n",
    "    filtered_list = songlist\n",
    "    \n",
    "    with zipfile.ZipFile(zipname, \"r\") as zf:\n",
    "        ziplist = zf.namelist()\n",
    "    \n",
    "    for song in songlist:\n",
    "        fname = \"sscs/\" + song\n",
    "        mix = fname + \"_mix.csv\"\n",
    "        s = fname + \"_S.csv\"\n",
    "        a = fname + \"_A.csv\"\n",
    "        t = fname + \"_T.csv\"\n",
    "        b = fname + \"_B.csv\"\n",
    "        if  (not mix in ziplist) or \\\n",
    "            (not s in ziplist) or \\\n",
    "            (not a in ziplist) or \\\n",
    "            (not t in ziplist) or \\\n",
    "            (not b in ziplist):\n",
    "                filtered_list.remove(song)\n",
    "                count += 1\n",
    "\n",
    "    print(f\"{count} songs not present and removed from scanlist.\")\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = checkIntegrity(sscs_get_split())\n",
    "validate = checkIntegrity(sscs_get_split('validate'))\n",
    "test = checkIntegrity(sscs_get_split('test'))\n",
    "\n",
    "train_conformity = [name_conformity(name) for name in train]\n",
    "validate_conformity = [name_conformity(name) for name in validate]\n",
    "test_conformity = [name_conformity(name) for name in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEM = 4 * 1024 * 1024 * 1024\n",
    "\n",
    "def csv_to_df(songname):\n",
    "    with zipfile.ZipFile(zipname) as zf:\n",
    "        fname = \"sscs/\" + songname\n",
    "        with zf.open(fname) as f:\n",
    "            df = pd.read_csv(f, header=None, engine='pyarrow')\n",
    "        df = df.T\n",
    "        return df\n",
    "    \n",
    "def df_to_hdf5(df, savename, keyname):\n",
    "    df.to_hdf(savename, keyname, mode='a',\n",
    "            format='table', complevel=9, complib='blosc')\n",
    "\n",
    "@ray.remote  \n",
    "def csv_to_hdf5(songname, songname_conformity, split='train'):\n",
    "    if(split == 'train'):\n",
    "        print(f\"\\rTrain split {train.index(songname)}/{len(train)}\", end='')\n",
    "    elif (split == 'validate'):\n",
    "        print(f\"\\rValidate split {validate.index(songname)}/{len(validate)}\", end='')\n",
    "    elif (split == 'test'):\n",
    "        print(f\"\\rTest split {test.index(songname)}/{len(test)}\", end='')\n",
    "    fnames   = [songname + \"_mix.csv\",\n",
    "                songname + \"_S.csv\",\n",
    "                songname + \"_A.csv\",\n",
    "                songname + \"_T.csv\",\n",
    "                songname + \"_B.csv\"] \n",
    "    keynames = ['mix', 'soprano', 'alto',\n",
    "                'tenor', 'bass']\n",
    "    savename = h5_pathname + \"Files/\" + songname_conformity + \".h5\"\n",
    "    try:\n",
    "        if(not os.path.exists(savename)):\n",
    "            for i in range(len(keynames)):\n",
    "                df = csv_to_df(fnames[i])\n",
    "                df_to_hdf5(df, savename, keynames[i])\n",
    "    except:\n",
    "        print(f\"Problematic file: {songname}\")\n",
    "        if(os.path.exists(savename)):\n",
    "            os.remove(savename)\n",
    "\n",
    "        try:\n",
    "            train.remove(songname)\n",
    "            train_conformity.remove(songname_conformity)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            validate.remove(songname)\n",
    "            validate_conformity.remove(songname_conformity)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            test.remove(songname)\n",
    "            test_conformity.remove(songname_conformity)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_train = [csv_to_hdf5.options(memory=MAX_MEM).remote(train[i],\n",
    "    train_conformity[i]) for i in range(len(train))]\n",
    "conv_train_get = ray.get(conv_train)\n",
    "\n",
    "conv_val = [csv_to_hdf5.options(memory=MAX_MEM).remote(validate[i],\n",
    "    validate_conformity[i]) for i in range(len(validate))]\n",
    "conv_val_get = ray.get(conv_val)\n",
    "\n",
    "conv_test = [csv_to_hdf5.options(memory=MAX_MEM).remote(test[i],\n",
    "    test_conformity[i]) for i in range(len(test))]\n",
    "conv_test_get = ray.get(conv_test)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_metadata = {}\n",
    "hdf5_metadata['train'] = train_conformity\n",
    "hdf5_metadata['validate'] = validate_conformity\n",
    "hdf5_metadata['test'] = test_conformity\n",
    "\n",
    "metadata_filename = h5_pathname + \"SynthSalienceChoralSet_hdf5_dataSplits.json\"\n",
    "with open(metadata_filename, \"w\") as metadata_file:\n",
    "    json.dump(hdf5_metadata, metadata_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
